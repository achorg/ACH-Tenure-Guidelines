# Digital Scholarship Assessment Notes (JD)

## 1) Emory University, Humanities Council:

### Criteria

Most significant: contribution to the field defined as original research or approach and impact on a community of scholars.

### Assessment process:

* Native format
* Informed judgments by scholars, including external

### Digitally specific criteria

* Relationship between design, content, medium
* Prevailing technical standards
* Long term viability

## 2) USC, Provost-Academic Senate University Research Committee and UCAPT

### Expectations: 

* Clarified at hiring: outputs, terms of assessment
* Recognize that digital work is collaborative, process-oriented, labor intensive

### Criteria:

* Describe methods, impacts, theoretical contributions 
* Describe process and labor
* Document review processes in funding agencies or other peer structures
* Describe roles in collaboration 

### Assessment process:

* Native format
* Informed judgments by reviewers with expertise

### Digitally specific:

* Peer review may occur before production in grant process
* Technical standards
* Design aesthetics, formal structure

## 3) Modern Language Association, Committee on Information Technology

## Expectations:

At hiring, the expectations for productivity, responsibilities for departmental support
* 
## Candidate responsibilities

* Ask for clarification of evaluation and support
* Negotiate and document roles in the department (clarify administrative and research work commitments)
* Document and explain the work and its value
  * Changing boundaries of research, teaching, administration
  * Infrastructure development and challenges
  * New collaborative relationships
* Document grant successes, network building and the terms on which the digital humanities community ascribes merit or value

## Assessment process:

* Written guidelines
* Engage qualified reviewers
* Respect medium specificity (native formats)
* Accessibility

## 4) AHA

### Defining distinctions:

* Digitally published work in a peer reviewed journal is equivalent to print
* Digital work that uses “methodologies, argumentation, or archival practices that differ from print practices” need their own assessment
* Might include: blogs, digital storytelling, social media, or new digital platforms

### Assessment criteria:

* Scholarly merit
* Native media

### Candidate responsibility:

* Explanatory narratives
* Explain and document development of the project 
* Make the scholarly contribution clear
* Discuss documents with chairs and committees
* Bring colleagues into the work
* Seek support and guidance in preparing promotion materials
* Consider the impact of evaluation processes in advance
 
### Departments’ responsibilities

* Become informed about developing contexts
* Before hiring: specify what counts as scholarly contributions
* Understand work that may be under constant evolution  / revision
* Understand how to assess tool and platform development
* Consider grant funding success as part of the assessment

### Professional association responsibilities

* Create a working group for digital scholarship and assessment
* Foster conversations in the profession/discipline
* Sustain a curated gallery of digital scholarship with criteria
* Promote reviews of digital scholarship* 


## 5) Laura Mandell, Texas A&M, Open Letter to Tenure and Promotion Committee

### Assessment process

* Candidate responsibility: submit for peer review
  * Scholarly Editions Committee, MLA 
  * NINES, 18thConnect, MESA, REKn, ModNets
  * Digital journals –same peer review process as print
  * Prestige rankings: rejection statistics, contributors’ profiles, editorial boards, circulation
  * Prizes
* Technical reviews By peer-review journals

### Criteria of Assessment:

* Digitally specific: digital media are not “incidental but integral”
* Roles in collaboration need to be spelled out and made explicitly

### Technical criteria:

* Use of a coding standard (such as TEI)
* Database design
* Solid design principles in the user experience / interface
* Interoperability with other resources
* Does the digital archive/project fulfill its project goals
* Assess digital archive production as an act of “curation” (filtering/selecting)
* Assess tool and platform production to enable computational and/or digital work by others without technical support
* Speaking engagements related to the project*

## 6) Professor Hacker (Adeline Koh guest post)

### Candidate responsibility:

* Educate the audience/committees by defining peers and audiences
* Educate the reviewers about the nature of your project—what kind of project it is
* Document the roles in collaborations
* Explain changes in peer review—“post-publication” vs. “pre-publication”
* Address issues of gatekeeping and new media (blog posts, tweets)

## 7) University of Nebraska, Lincoln 

### Digital specificity:

* Technical component lacking in traditional scholarship

### Candidate responsibility:

* How does the digital format contribute to the uniqueness and originality of the scholarship

### Assessment criteria:

* Peer review of sites or tools
* Collaborations with related projects at other institutions
* Links from other sites to the scholar’s research
* Use of standards (TEI, XML etc.)
* Technical innovation and sophistication
* Collaboration with experts in design and implementation documented
* Long term viability
* Compatibility of design, content, and medium
* Grant funding received (peer review process)
* Pedagogical application
* Conference presentations
* Print publications from the project

## 8) Nines Institute on Evaluating Digital Scholarship

### Assessment:

* In the original medium and form/format in which scholarship was created
* Recognize the collaborative nature of digital projects
* Get each component of the projects reviewed by relevant experts

### Considerations:

* Organization of knowledge
  * What community is concerned with this scholarship.
  * What is the content – what decisions about inclusion/exclusion and how are these rhetorical choices?
  * Have relevant standards for digitization been followed and documented?
  * How do the elements/components interact (essays, commentaries etc.)
  * Is the data structure solid
  * Does the interface communicate effectively
* Dissemination
  * Is the project able to reach targeted audiences
  * Is the project linked to other projects
  * Where is the project hosted
* Evaluation internal to the project
  * Have user experiences been tested?
  * Has the project been peer reviewed?
  * Have papers been published on the project?
* Sustainability
  * Long term development plans?
  * Potential for evolving or changing over time? 

## Other Refs:

* Bethany Nowviskie, The Elaboration of Collaborative Digital Scholarship
  * Document the process of co-creation
  * Balance individual agency with inclusive statements about contributions of others
  * Clarify roles explicitly in scholarly collaborations 
  * Recognize contributions
* Lynn C. Hattendorf Westney, (2000) "A trivial pursuit? Information technology and the tenure track", Campus-Wide Information Systems, Vol. 17 Iss: 4, pp.113 - 119 http://www.emeraldinsight.com/doi/abs/10.1108/10650740010350684?journalCode=cwis
* Teresa Neely, The Impact of Electronic Publications on Promotion and Tenure Decisions, Leading Ideas, October 1999 http://old.arl.org/bm~doc/li10.pdf

